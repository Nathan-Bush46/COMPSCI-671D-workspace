{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "1    237\n",
       "0    195\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plot\n",
    "\n",
    "raw_training = pd.read_csv(\"data/hw1_q3_train_data.csv\")\n",
    "raw_testing = pd.read_csv(\"data/hw1_q3_test_data.csv\")\n",
    "\n",
    "df_train_x = raw_training.iloc[:, :-1]\n",
    "df_train_y = raw_training.iloc[:, -1]\n",
    "df_test_x = raw_testing.iloc[:, :-1]\n",
    "df_test_y = raw_testing.iloc[:, -1]\n",
    "\n",
    "\n",
    "#raw_training.head(5)\n",
    "df_train_y.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dataframe(df,normalization_params):\n",
    "    normalized_df = df.apply(lambda column: column / normalization_params[column.name])\n",
    "    return normalized_df\n",
    "\n",
    "normalization_params = df_train_x.max()\n",
    "\n",
    "##normalizatio z-score\n",
    "# normalization_params_mean = df_train_x.mean()\n",
    "# normalization_params_std = df_train_x.std()\n",
    "# normalization_params = (df_train_x - normalization_params_mean) / normalization_params_std\n",
    "\n",
    "df_train_x_norm = normalize_dataframe(df_train_x,normalization_params)\n",
    "df_test_x_norm = normalize_dataframe(df_test_x,normalization_params)\n",
    "\n",
    "#print(df_train_x_norm)\n",
    "\n",
    "#print(df_test_x_norm.loc[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3a.i\n",
    "I normalized the data from 0 to 1 by dividing each column by it's max (in the training set). This is simple way to normalize but can be effected by outliers. I'll try training with this first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "1    237\n",
      "0    195\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5486111111111112"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = df_train_y.value_counts()\n",
    "print(counts)\n",
    "237/(237+195)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3a.i\n",
    "\n",
    "Given: \n",
    "   1.  The dataset shows a slight imbalance in class distribution (237 to 195). (could go either way but lean toward f1) \n",
    "   2.  We are trying to determine if a mushroom is edible, so False Negatives (undetected poisons mushroom) and False Positives (normal  mushrooms labeled as poisons) should be heavy considered. (F1 is best)\n",
    "\n",
    "   Therefore I would use F1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3b.i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def euclidean_distance(point1, point2):   \n",
    "    \"\"\"takes two np.arrays \n",
    "    \"\"\"\n",
    "    return np.sqrt(np.sum(np.square(point1 - point2)))\n",
    "\n",
    "def knn(n,point_to_classify, df_train_x, df_train_y, threshold):\n",
    "    \"\"\" returns (class)\n",
    "    \"\"\"\n",
    "    k = int(np.sqrt(n))\n",
    "    if(k % 2 == 0):\n",
    "        k+=1\n",
    "    assert k%2 != 0\n",
    "\n",
    "    distances = df_train_x.apply(lambda row: euclidean_distance(point_to_classify, row), axis=1)\n",
    "\n",
    "    result_df = pd.DataFrame({'distances': distances, 'labels': df_train_y})\n",
    "    sorted_result_df = result_df.sort_values(by='distances',ascending=True)\n",
    "    knn = sorted_result_df.head(k)\n",
    "    label_counts = knn['labels'].value_counts()\n",
    "    number_of_1 = label_counts.get(1, 0)\n",
    "    number_of_0 = label_counts.get(0, 0)\n",
    " #   print(number_of_1,number_of_0)\n",
    "    if(number_of_1/(number_of_1+number_of_0) >= threshold):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "#point = np.array((871,6,2,7,0.6680444512544724,960,11,0.0273721330556057)) \n",
    "#point = df_test_x_norm.loc[1]\n",
    "#n = len(df_train_x_norm.index)\n",
    "\n",
    "#test_point_class = knn(n, point,df_train_x_norm,df_train_y)\n",
    "#print(test_point_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(df_train_x_norm.index)\n",
    "classes_even = df_test_x_norm.apply(lambda row: knn(n, row, df_train_x_norm, df_train_y, 0.5), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(df_train_x_norm.index)\n",
    "classes_uneven = df_test_x_norm.apply(lambda row: knn(n, row, df_train_x_norm, df_train_y, 0.4), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "even\n",
      "Accuracy: 0.5864\n",
      "Recall: 0.6298\n",
      "Precision: 0.6298\n",
      "F1: 0.6298\n",
      "uneven\n",
      "Accuracy: 0.6049\n",
      "Recall: 0.8508\n",
      "Precision: 0.6039\n",
      "F1: 0.7064\n"
     ]
    }
   ],
   "source": [
    "def evaluate(test_predict,test_actual):\n",
    "    TP = 0\n",
    "    FP = 0 \n",
    "    FN = 0 \n",
    "    TN = 0\n",
    "    n_test =len(test_actual)\n",
    "    for i in range(0,n_test):\n",
    "        if (test_predict[i] == 1 and test_actual[i] == 1):\n",
    "            TP += 1\n",
    "        elif(test_predict[i] == 0 and test_actual[i] == 1):\n",
    "            FN += 1\n",
    "        elif(test_predict[i] == 0 and test_actual[i] == 0):\n",
    "            TN += 1\n",
    "        elif(test_predict[i] == 1 and test_actual[i] == 0):\n",
    "            FP += 1\n",
    "\n",
    "    accuracy = (TP +TN)/(TP+FP+FN+TN)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    recall = (TP)/(TP+FN)\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    precision = (TP)/(TP+FP)\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    f1 = (2*TP)/(2*TP+FP+FN)\n",
    "    print(f\"F1: {f1:.4f}\")\n",
    "    #print(TP,FP)\n",
    "    #print(FN,TN)\n",
    "\n",
    "test_predict_even = classes_even.to_list()\n",
    "test_predict_uneven = classes_uneven.to_list()\n",
    "\n",
    "test_actual = df_test_y.to_list()\n",
    "print(\"even\")\n",
    "evaluate(test_predict_even,test_actual)\n",
    "print(\"uneven\")\n",
    "evaluate(test_predict_uneven,test_actual)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: 0.5864\n",
    "\n",
    "Recall: 0.6298\n",
    "\n",
    "Precision: 0.6298\n",
    "\n",
    "F1: 0.6298"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5864\n",
      "recall: 0.6298\n",
      "precision: 0.6298\n",
      "f1: 0.6298\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score\n",
    "\n",
    "\n",
    "# Assuming X_train, y_train, X_test, and y_test are already defined\n",
    "y_test = df_test_y\n",
    "X_test = df_test_x_norm\n",
    "X_train = df_train_x_norm\n",
    "y_train = df_train_y\n",
    "N = X_train.shape[0]\n",
    "\n",
    "# Calculate k as the square root of N, rounded to the nearest odd number\n",
    "k = int(np.sqrt(N))\n",
    "if k % 2 == 0:\n",
    "    k += 1\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"recall: {recall:.4f}\")\n",
    "print(f\"precision: {precision:.4f}\")\n",
    "print(f\"f1: {f1:.4f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
